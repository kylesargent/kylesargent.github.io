---
layout: post
title:  "ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image"
date:   2021-10-25 00:00:00 +00:00
image: /videos/motorcycle_cropped.gif
venue: <em>CVPR</em>, 2024.
categories: research
authors: "<strong>Kyle Sargent</strong>, Zizhang Li, Tanmay Shah, Charles Herrmann, Hong-Xing Yu, Yunzhi Zhang, Eric Ryan Chan, Dmitry Lagun, Li Fei-Fei, Deqing Sun, Jiajun Wu"
arxiv: https://kylesargent.github.io/zeronvs
projectpage: https://kylesargent.github.io/zeronvs
---
We train a 3D-aware diffusion model, ZeroNVS on a mixture of scene data sources that capture object-centric, indoor, and outdoor scenes. This enables zero-shot SDS distillation of 360-degree NeRF scenes from a single image. Our model sets a new state-of-the-art result in LPIPS on the DTU dataset in the zero-shot setting. We also use the MipNeRF-360 dataset as a benchmark for single-image NVS.